{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras import layers, optimizers\n",
    "from keras import preprocessing\n",
    "from sklearn import model_selection\n",
    "\n",
    "import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "fire_images = glob.glob(\"fire_images/*.*\")\n",
    "normal_images = glob.glob(\"normal_images/*.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pandas dataframe for the images filepaths\n",
    "ls_fire = [['fire_images', i.split(\"/\")[1], '1'] for i in fire_images]\n",
    "ls_normal = [['normal_images', i.split(\"/\")[1], '0'] for i in normal_images]\n",
    "ls_fire.extend(ls_normal)\n",
    "df_fire = pd.DataFrame(ls_fire, columns=['Folder', 'filename', 'label'])\n",
    "print(len(df_fire[df_fire['Folder'] == 'fire_images']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test, y_train, y_test = model_selection.train_test_split(df_fire.drop(columns=['label']), df_fire['label'])\n",
    "df_train['label'] = pd.Series((int(y) for y in y_train), index=df_train.index)\n",
    "df_test['label'] = pd.Series((int(y) for y in y_test), index=df_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generator for training\n",
    "def data_gen(df, batch_size):\n",
    "    while True:\n",
    "        x_batch = np.zeros((batch_size, 800, 800, 3))\n",
    "        y_batch = np.zeros((batch_size, 1))\n",
    "        for j in range(len(df)//batch_size):\n",
    "            b = 0\n",
    "            for m, k in zip(df['filename'].values[j*batch_size:(j+1)*batch_size], df['label'].values[j*batch_size:(j+1)*batch_size]):\n",
    "                img = Image.open('{}/{}'.format(df[df['filename'] == m]['Folder'].values[0], m))\n",
    "                image_red = img.resize((800, 800))\n",
    "                image_arr = preprocessing.image.img_to_array(image_red)\n",
    "                if image_arr.shape == (800, 800, 3):\n",
    "                    x_batch[b] = preprocessing.image.img_to_array(image_red)\n",
    "                    y_batch[b] = k\n",
    "                b += 1\n",
    "            yield (x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model And Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_baseline_fire():\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(800, 800, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten() \n",
    "    ])\n",
    "    opt = optimizers.SGD(lr=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train model and get it's history\n",
    "print('Training Model')\n",
    "baseline_fire = define_baseline_fire()\n",
    "history = baseline_fire.fit_generator(generator=data_gen(df_train, 10), steps_per_epoch=len(df_train)//10, epochs=10)\n",
    "\n",
    "# Evaluate model\n",
    "print('Evaluating Model')\n",
    "_, acc = model.evaluate_generator(data_get(df_test, 100), steps=len(df_test)//100, verbose=0)\n",
    "print('> %.3f' % (acc * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "print('Evaluating Model')\n",
    "_, acc = baseline_fire.evaluate_generator(data_gen(df_test, 10), steps=len(df_test)//10)\n",
    "print('> %.3f' % (acc * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_diagnostics(history):\n",
    "    # Plot loss\n",
    "    plt.subplot(211)\n",
    "    plt.title('Cross Entropy Loss')\n",
    "    plt.plot(history.history['loss'], color='blue', label='train')\n",
    "    plt.plot(history.history['validation_loss'], color='orange', label='test')\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(212)\n",
    "    plt.title('Classification Accuracy')\n",
    "    plt.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "    \n",
    "summarize_diagnostics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
